{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **PCA(Principle Component Analysis)**"
      ],
      "metadata": {
        "id": "tXA0pS8EOxEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA는 차원 축소 기법이면서, 데이터 압축 기법이기도 하고, 노이즈 제거기법이기도함.\n"
      ],
      "metadata": {
        "id": "2JUweVPOOYKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 입력 데이터의 공분산 행렬을 기반으로 고유벡터를 생성하고 이렇게 구한 고유 벡터에 입력 데이터를 선형 변환하여 차원을 축소하는 방법이다.\n",
        "- 차원은 곧 입력 데이터의 피처를 뜻하므로 데이터 압축 기법으로 볼 수도 있다.\n",
        "- PCA는 고유값이 가장 큰, 즉 데이터의 분산이 가장 큰 순으로 주성분 벡터를 추출하는데, 가장 나중에 뽑힌 벡터보다 가장 먼저 뽑힌 벡터가 데이터를 더 잘 설명할 수 있기 때문에 노이즈 제거 기법이라고도 불린다."
      ],
      "metadata": {
        "id": "mNaYjo8AOxAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LSA, LDA, SVD 등의 약자들이 어떤 뜻이고 서로 어떤 관계인가**"
      ],
      "metadata": {
        "id": "MDQ7aqAPOw_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- PCA는 **Principle Component Analysis**의 약자로 데이터의 공분산 행렬을 기반으로 고유벡터를 생성하고 이렇게 구한 고유 벡터에 입력 데이터를 선형 변환하여 차원을 축소하는 방법이다.\n",
        "- SVD는 **Singular Value Decomposition**의 약자로 PCA와 유사한 행렬 분해 기법을 사용하나 정방 행렬(square matrix)를 분해하는 PCA와 달리 행과 열의 크기가 다른 행렬에도 적용할 수 있다.\n",
        "- LSA는 **Latent Semantic Analysis**의 약자로 잠재 의미 분석을 말하며, 주로 토픽 모델링에 자주 사용되는 기법이다.\n"
      ],
      "metadata": {
        "id": "XTTY_Bl7OwtA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- LSA는 DTM(Document-Term Matrix)이나 TF-IDF(Term Frequency-Inverse Document Frequency) 행렬에 Truncated SVD를 적용하여 차원을 축소시키고, 단어들의 잠재적인 의미를 이끌어낸다.\n",
        "- Truncated SVD는 SVD와 똑같으나 상위 n개의 특이값만 사용하는 축소 방법이다. 이 방법을 쓸 경우 원 행렬로 복원할 수 없다.\n"
      ],
      "metadata": {
        "id": "-u-8_EaPR4F9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- LDA는 Latent Dirichlet Allocation 혹은 Linear Discriminant Analysis의 약자이다.\n",
        " - 전자는 토픽모델링에 사용되는 기법 중 하나로 LSA와는 달리 단어가 특정 토픽에 존재할 확률과 문서에 특정 토픽이 존재할 확률을 결합확률로 추정하여 토픽을 추정하는 기법을 말한다.\n",
        " - 후자는 차원축소기법 중 하나로 분류하기 쉽도록 클래스 간 분산을 최대화하고 클래스 내부의 분산은 최소화하는 방식을 말한다."
      ],
      "metadata": {
        "id": "OLW85EmFSD43"
      }
    }
  ]
}